{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExMN0Dq1J93s"
   },
   "source": [
    "# Business Understanding\n",
    "\n",
    "## 1. Introduction: Real-World Problem\n",
    "In today's digital world, social media platforms like Twitter serve as a major outlet for public opinions and feedback. For companies like **Apple**, understanding how customers perceive their products on Twitter is crucial for improving product development, marketing strategies, and customer relationships.\n",
    "\n",
    "However, manually analyzing thousands of tweets to understand sentiment is a daunting task. **Natural Language Processing (NLP)** can automate this process, allowing businesses to quickly assess public sentiment on a large scale.\n",
    "\n",
    "The goal of this project is to develop an **NLP model** that can automatically classify the sentiment of a tweet as **positive**, **negative**, or **neutral**. This will help Apple and other stakeholders make informed decisions based on public sentiment.\n",
    "\n",
    "## 2. Stakeholders\n",
    "The following stakeholders can benefit from the sentiment analysis model:\n",
    "\n",
    "### Primary Stakeholders:\n",
    "- **Apple (or similar tech companies)**:\n",
    "   - **Marketing Teams**: Can use the model to track customer reactions to marketing campaigns, product launches, and other brand activities.\n",
    "   - **Product Development Teams**: Can identify which features are well-received and which need improvement based on real-time public sentiment.\n",
    "\n",
    "### Secondary Stakeholders:\n",
    "- **Customers**:\n",
    "   - Customers can see how their opinions are reflected in public sentiment trends, and how other users feel about Apple products.\n",
    "\n",
    "- **Competitors (e.g., Google)**:\n",
    "   - Competitors can analyze sentiment around Apple products to gain insights into Apple's strengths and weaknesses, guiding their own product strategies.\n",
    "\n",
    "## 3. How the Project Helps Stakeholders\n",
    "The sentiment analysis model will provide the following benefits to stakeholders:\n",
    "- **For Apple**:\n",
    "   - Helps monitor real-time public sentiment about Apple products, enabling faster response to customer feedback.\n",
    "- **For Marketing Teams**:\n",
    "   - Allows for the measurement of campaign effectiveness and helps adjust marketing strategies based on sentiment.\n",
    "- **For Product Development Teams**:\n",
    "   - Provides insights into which features or aspects of the product are favored or disliked by customers, aiding in future product improvements.\n",
    "\n",
    "## 4. Conclusion: Implications for the Real-World Problem\n",
    "By automating sentiment analysis on Twitter, Apple and other stakeholders can gain valuable insights without the need for extensive manual work. The ability to track public sentiment in real-time means that Apple can be more responsive to customer feedback, optimize marketing efforts, and improve product offerings. This can ultimately lead to more successful product launches and higher customer satisfaction.\n",
    "\n",
    "## 5. Business Value Summary\n",
    "This NLP sentiment analysis model provides actionable insights that will help Apple make informed business decisions quickly and efficiently. By understanding public sentiment, Apple can enhance customer engagement, drive product innovation, and maintain a competitive edge in the market.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt9jf1qTKIFu"
   },
   "source": [
    "# Data Understanding\n",
    "\n",
    "## 1. Data Source\n",
    "The dataset used for this project comes from **CrowdFlower**, via **data.world**. The dataset contains over 9,000 tweets that have been manually rated for sentiment by human annotators. Each tweet is labeled with one of three sentiment categories: **positive**, **negative**, or **neutral**.\n",
    "\n",
    "### Source Summary:\n",
    "- **Dataset**: Apple Twitter Sentiment (CrowdFlower)\n",
    "- **Source**: [data.world - Apple Twitter Sentiment](https://data.world/crowdflower/)\n",
    "\n",
    "This dataset is highly relevant for the task at hand, as it directly addresses the need for an automated system to classify public sentiment on Twitter about Apple products.\n",
    "\n",
    "## 2. Dataset Size and Descriptive Statistics\n",
    "The dataset consists of 9,000+ tweets with the following key features:\n",
    "\n",
    "- **Tweet**: The textual content of the tweet (string).\n",
    "- **Sentiment**: The sentiment label assigned to each tweet (categorical: Positive, Negative, Neutral).\n",
    "  \n",
    "### Descriptive Statistics:\n",
    "Let's take a quick look at some basic statistics for the sentiment labels and the tweet content:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0rNAirHKQyj"
   },
   "source": [
    "\n",
    "This section covers:\n",
    "- **The data source** and how itâ€™s relevant to the problem.\n",
    "- **The size and structure** of the dataset with basic descriptive statistics and an initial look at sentiment distribution.\n",
    "- **Justification for including features**, like the tweet text and sentiment labels, as critical inputs for solving the problem.\n",
    "- **Limitations** of the data that may impact model performance, such as class imbalance or labeling biases.\n",
    "\n",
    "Does this structure look good to you? Feel free to adapt it as needed or let me know if you'd like further refinements!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p5gAPv3pJDv4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl3BE7rBLGXs"
   },
   "source": [
    "1. Loading the Dataset\n",
    "Justification: Loading the dataset is the first step in any data analysis project. It is essential to read in the raw data before any processing or analysis can occur. In this case, reading the CSV file into a pandas DataFrame allows us to efficiently explore and manipulate the data for further steps.\n",
    "\n",
    "Why it's appropriate: This step allows us to move from raw data stored in an external file to a structured format that we can easily analyze and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YrXs2O-MKULt"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Apple-Twitter-Sentiment-DFE.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "Y8cUS-6SKcxT",
    "outputId": "b7512b13-c5f0-4b49-9b0b-16275581ea13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623495513</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>Mon Dec 01 19:30:03 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\nnot_relevant</td>\n",
       "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623495514</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>Mon Dec 01 19:43:51 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>623495515</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mon Dec 01 19:50:28 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>My cat only chews @apple cords. Such an #Apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>623495516</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>Mon Dec 01 20:26:34 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>I agree with @jimcramer that the #IndividualIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623495517</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 12:14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>Mon Dec 01 20:29:33 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nobody expects the Spanish Inquisition #AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  623495513     True      golden                  10               NaN   \n",
       "1  623495514     True      golden                  12               NaN   \n",
       "2  623495515     True      golden                  10               NaN   \n",
       "3  623495516     True      golden                  17               NaN   \n",
       "4  623495517    False   finalized                   3    12/12/14 12:14   \n",
       "\n",
       "  sentiment  sentiment:confidence                            date  \\\n",
       "0         3                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
       "1         3                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
       "2         3                1.0000  Mon Dec 01 19:50:28 +0000 2014   \n",
       "3         3                0.5848  Mon Dec 01 20:26:34 +0000 2014   \n",
       "4         3                0.6474  Mon Dec 01 20:29:33 +0000 2014   \n",
       "\n",
       "             id            query   sentiment_gold  \\\n",
       "0  5.400000e+17  #AAPL OR @Apple  3\\nnot_relevant   \n",
       "1  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "2  5.400000e+17  #AAPL OR @Apple                3   \n",
       "3  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "4  5.400000e+17  #AAPL OR @Apple              NaN   \n",
       "\n",
       "                                                text  \n",
       "0  #AAPL:The 10 best Steve Jobs emails ever...htt...  \n",
       "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...  \n",
       "2  My cat only chews @apple cords. Such an #Apple...  \n",
       "3  I agree with @jimcramer that the #IndividualIn...  \n",
       "4       Nobody expects the Spanish Inquisition #AAPL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3886 entries, 0 to 3885\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   sentiment     3886 non-null   int32 \n",
      " 1   text          3886 non-null   object\n",
      " 2   cleaned_text  3886 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 76.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5SFb5wOKmSc",
    "outputId": "a7576e9f-0e88-4b2f-eb4c-ab7d4e01c88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (3886, 12)\n",
      "Columns in dataset: Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'sentiment', 'sentiment:confidence', 'date', 'id',\n",
      "       'query', 'sentiment_gold', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset's shape and column names\n",
    "print(f\"Shape of dataset: {df.shape}\")\n",
    "print(f\"Columns in dataset: {df.columns}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kklFFXQWLUab"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBpPeG60LWxD"
   },
   "source": [
    "Removing Unnecessary Columns\n",
    "\n",
    "Objective: Remove irrelevant columns that won't be used for analysis, making the dataset cleaner and more focused.\n",
    "\n",
    "Justification:\n",
    "\n",
    "Irrelevant columns: These columns provide metadata or details that do not contribute to the sentiment analysis model. Removing them streamlines the dataset and improves processing speed.\n",
    "\n",
    "By dropping columns such as id, query, and _unit_id, we focus only on the features that matter: the tweet text and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bFHmkuqSK93D",
    "outputId": "47f4d517-bf11-41d3-fa7f-7ba8f4f71bcd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>My cat only chews @apple cords. Such an #Apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I agree with @jimcramer that the #IndividualIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Nobody expects the Spanish Inquisition #AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0         3  #AAPL:The 10 best Steve Jobs emails ever...htt...\n",
       "1         3  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...\n",
       "2         3  My cat only chews @apple cords. Such an #Apple...\n",
       "3         3  I agree with @jimcramer that the #IndividualIn...\n",
       "4         3       Nobody expects the Spanish Inquisition #AAPL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that are not useful for analysis\n",
    "df.drop(columns=['_unit_id', '_golden', '_unit_state', '_trusted_judgments', '_last_judgment_at', 'sentiment:confidence', 'date', 'id', 'query', 'sentiment_gold'], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TLf5wFVLjak"
   },
   "source": [
    "Handling Missing Data\n",
    "Objective: Identify and handle any missing values in the dataset. Missing data can impact model performance, so we either drop or impute it based on the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "c-b9-IkQLZw8",
    "outputId": "ad35c6b5-d0cc-47b8-fa84-b3d68b4af3dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Drop rows with missing text or sentiment labels\n",
    "df.dropna(subset=['text', 'sentiment'], inplace=True)\n",
    "\n",
    "# Verify that there are no missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixekb13JLotc"
   },
   "source": [
    "Justification:\n",
    "\n",
    "Missing text or sentiment: If the tweet text or sentiment is missing, the data is incomplete and can't be used for analysis. Hence, we drop these rows.\n",
    "\n",
    "Handling missing data is crucial as it ensures that the model doesn't train on incomplete or unreliable information, improving its accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSBQxEm4LrVL"
   },
   "source": [
    "## Encoding Sentiment Labels\n",
    "\n",
    "Objective: Convert the sentiment labels (positive, negative, neutral) into numerical values so they can be used by machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo4KXdbRL2Y7"
   },
   "source": [
    "Justification:\n",
    "\n",
    "Label Encoding: Machine learning models can only work with numerical data. Encoding the categorical sentiment labels ensures the model can process them.\n",
    "\n",
    "Why it's appropriate: Sentiment analysis is inherently a classification task. Label encoding converts categories (positive, negative, neutral) into numerical labels (0, 1, 2), making them ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "45AgzpJnLlnr",
    "outputId": "81806b76-d355-4945-9715-0d09715d9305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2162\n",
       "0    1219\n",
       "2     423\n",
       "3      82\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the sentiment labels\n",
    "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Verify the encoding\n",
    "df['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxnPxZQ2L5cj"
   },
   "source": [
    "## Text Preprocessing\n",
    "Objective: Clean the text data to ensure it is in a format that can be processed by the machine learning model. This includes removing special characters, stop words, and unnecessary spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWltmhrYLxtE",
    "outputId": "38d117b8-322a-4de7-da0c-07c6057ae2c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the stopwords resource\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3sbslCPMU-L",
    "outputId": "3111d91e-f48b-4dfb-ea45-6a1bcd7e24d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKOEi4ZHL8mU",
    "outputId": "3eec39a5-8944-4992-813f-83179518dccd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Return cleaned text as a string\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZk7ZckuNJqT"
   },
   "source": [
    "Feature Engineering (Text Vectorization)\n",
    "Objective: Convert the cleaned text into a numerical format that machine learning models can understand. We'll use TF-IDF for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Hhg2rHVMn7F",
    "outputId": "842d2b76-c747-48e7-9c38-ca63b79209ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3886, 5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features to avoid overfitting\n",
    "\n",
    "# Fit and transform the 'text' column\n",
    "X = vectorizer.fit_transform(df['text']).toarray()\n",
    "\n",
    "# Verify the shape of the feature matrix\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1is4i02OBHr",
    "outputId": "32f90a76-c2b2-4d04-a886-9fa0f680c510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sentiment', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names of your dataframe\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhcsZOdOOluU",
    "outputId": "d4c1bf92-03c5-414c-de64-3fc308956de5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4eBDxOtOtTk",
    "outputId": "0b54ceb6-9c65-4818-c47f-4c3535782b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\User/nltk_data', 'C:\\\\Users\\\\User\\\\anaconda3\\\\envs\\\\learn-env\\\\nltk_data', 'C:\\\\Users\\\\User\\\\anaconda3\\\\envs\\\\learn-env\\\\share\\\\nltk_data', 'C:\\\\Users\\\\User\\\\anaconda3\\\\envs\\\\learn-env\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DxtUM8dZO15T"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/root/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4naZGq4O3D8",
    "outputId": "acc035b0-af0e-4d0a-ba80-c78986115068"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXQtzM35O5NM",
    "outputId": "d7eef131-af1e-4c47-f27a-0c8af78185fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2Y0H2dVPGtJ",
    "outputId": "339e01f4-9091-46b2-f7a3-6e603f52f47e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "He_DA4tlPKN9"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zU1ADVDYPNPE",
    "outputId": "1f9de7e5-9fc8-4f9c-e1d9-d0136714d6ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punkt tokenizer is available!\n"
     ]
    }
   ],
   "source": [
    "# Check if 'punkt' is available\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "try:\n",
    "    word_tokenize(\"This is a test sentence.\")\n",
    "    print(\"Punkt tokenizer is available!\")\n",
    "except LookupError as e:\n",
    "    print(\"Error: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkabNohdOHuj",
    "outputId": "c46b1933-2c8b-4562-865b-75b4c57273bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  #AAPL:The 10 best Steve Jobs emails ever...htt...   \n",
      "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...   \n",
      "2  My cat only chews @apple cords. Such an #Apple...   \n",
      "3  I agree with @jimcramer that the #IndividualIn...   \n",
      "4       Nobody expects the Spanish Inquisition #AAPL   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                aaplthe best steve jobs emails ever  \n",
      "1  rt jpdesloges aapl stock miniflash crash today...  \n",
      "2                    cat chews apple cords applesnob  \n",
      "3  agree jimcramer individualinvestor trade apple...  \n",
      "4            nobody expects spanish inquisition aapl  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Return cleaned text as a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the cleaning function to the 'text' column to create 'cleaned_text'\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Verify the first few rows to ensure 'cleaned_text' is created\n",
    "print(df[['text', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_WS8LO1NlqL"
   },
   "source": [
    "Visualizations part of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58ASEderNp_L"
   },
   "source": [
    "## Class Distribution (Sentiment Distribution)\n",
    "Bar Plot to show the distribution of sentiments in your dataset (e.g., how many positive, negative, and neutral sentiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "Y3pPPihTNLy0",
    "outputId": "c73ea491-aab5-4756-9796-58dc663b6983"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='sentiment', data=df)\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9p1ke4dNwAT"
   },
   "source": [
    "#Word Cloud for Most Frequent Terms\n",
    "Visualize the most common words in your dataset, which can give you an idea of the frequent terms in the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsP0FFLRPgok",
    "outputId": "31ece707-29d5-4d60-886f-b776ad1120d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wordcloud\n",
      "  Downloading wordcloud-1.9.4-cp38-cp38-win_amd64.whl (300 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from wordcloud) (8.0.0)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from wordcloud) (1.22.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from wordcloud) (3.7.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (1.2.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (4.55.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (2.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (20.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (2.8.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from matplotlib->wordcloud) (6.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from packaging>=20.0->matplotlib->wordcloud) (1.15.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\user\\anaconda3\\envs\\learn-env\\lib\\site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib->wordcloud) (3.3.0)\n",
      "Installing collected packages: wordcloud\n",
      "Successfully installed wordcloud-1.9.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "zxK9F1r6Nt0U",
    "outputId": "304b39eb-177a-4bfa-f81a-65779825d0dc"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransposedFont' object has no attribute 'getbbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-3b96d2c8242f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Generate the word cloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mwordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Plot the word cloud\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \"\"\"\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    622\u001b[0m         \"\"\"\n\u001b[0;32m    623\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mfont_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 self.generate_from_frequencies(dict(frequencies[:2]),\n\u001b[0m\u001b[0;32m    454\u001b[0m                                                max_font_size=self.height)\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# find font sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    509\u001b[0m                     font, orientation=orientation)\n\u001b[0;32m    510\u001b[0m                 \u001b[1;31m# get size of resulting text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                 \u001b[0mbox_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m                 \u001b[1;31m# find possible places using integral image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtextbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    565\u001b[0m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"RGBA\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0membedded_color\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 567\u001b[1;33m         bbox = font.getbbox(\n\u001b[0m\u001b[0;32m    568\u001b[0m             \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstroke_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TransposedFont' object has no attribute 'getbbox'"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine all cleaned text into a single string\n",
    "all_text = ' '.join(df['cleaned_text'])\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.title('Most Frequent Words in the Tweets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyigpVgXPpZc"
   },
   "source": [
    "##Top Positive and Negative Words\n",
    "You can visualize the most frequent words in positive and negative sentiment categories. Here's a quick way to extract and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0edGuD5TNzyc",
    "outputId": "8cce4414-e1da-4ec2-b0a1-9edbaa32bb96"
   },
   "outputs": [],
   "source": [
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQ4i7hGpPsjl"
   },
   "outputs": [],
   "source": [
    "#filter for positive and negative tweets\n",
    "positive_tweets = df[df['sentiment'] == 1]\n",
    "negative_tweets = df[df['sentiment'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nZX7VrUDP9Kz"
   },
   "outputs": [],
   "source": [
    "#Ectract text for generation\n",
    "positive_text = ' '.join(positive_tweets['cleaned_text'])\n",
    "negative_text = ' '.join(negative_tweets['cleaned_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "jYV-4YxEQC0E",
    "outputId": "10331e1d-8608-41c1-e8b1-0d3be2066841"
   },
   "outputs": [],
   "source": [
    "#Generate worldcloud plot\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate word clouds for both positive and negative sentiments\n",
    "positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_text)\n",
    "negative_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(negative_text)\n",
    "\n",
    "# Plot the word clouds\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(positive_wordcloud, interpolation='bilinear')\n",
    "plt.title(\"Positive Sentiment\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(negative_wordcloud, interpolation='bilinear')\n",
    "plt.title(\"Negative Sentiment\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Iug9z4UQVki"
   },
   "source": [
    "##**Modeling**\n",
    "In this section, we will build multiple models iteratively, starting from a simple baseline model and progressively adding more complexity. We will compare the performance of each model and justify the improvements over the previous ones based on the results. The goal is to demonstrate an effective approach to model-building, starting from a basic model and moving toward more advanced techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vR8PrFNFQo7c",
    "outputId": "6ce19297-3f39-4f2f-e945-87fd1dbee105"
   },
   "outputs": [],
   "source": [
    "#Train and test splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X' is the feature matrix (TF-IDF features) and 'y' is the target variable (sentiment)\n",
    "X = vectorizer.transform(df['cleaned_text']).toarray()  # Or you can use the vectorized version from earlier\n",
    "y = df['sentiment']  # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the training and test sets\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5c-zh6DQcUU"
   },
   "source": [
    "##1. Baseline Model: Logistic Regression\n",
    "Model Description:\n",
    "We begin by training a Logistic Regression model as our baseline. Logistic Regression is a simple yet effective model for binary classification tasks. It will provide us with an initial benchmark to compare more complex models against.\n",
    "\n",
    "Why This Model:\n",
    "Logistic Regression is chosen for its simplicity and ease of interpretation. As the simplest model in the family of linear classifiers, it serves as a good starting point.\n",
    "\n",
    "#### Evaluation\n",
    "We used **accuracy** and **classification report** to evaluate the baseline model, which provides insight into the precision, recall, and F1-score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5jTmVI_QHMc",
    "outputId": "6e86e126-072c-46e1-de7e-9e32ef6b94fc"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train the baseline Logistic Regression model\n",
    "baseline_model = LogisticRegression(max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "baseline_y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_y_pred)\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PedTdC8QQ3Hd"
   },
   "source": [
    "##2. Improved Model: Random Forest Classifier\n",
    "Model Description:\n",
    "To improve upon the baseline Logistic Regression model, we introduce a Random Forest Classifier. Random Forest is an ensemble method that builds multiple decision trees and combines their results to improve prediction accuracy.\n",
    "\n",
    "Why This Model:\n",
    "Random Forest is known for its ability to handle more complex relationships and interactions between features. It is also less prone to overfitting compared to individual decision trees, making it a strong candidate for improving model performance.\n",
    "\n",
    "#### Evaluation\n",
    "We evaluated Random Forest using the same metrics (accuracy, precision, recall, and F1-score) to compare its performance with the baseline model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHCPc1TjQiqU",
    "outputId": "57a83537-c161-4e27-9917-f439c4f852fa"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY3WVgUgQ_AT"
   },
   "source": [
    "##3. Further Improvement: Support Vector Machine (SVM)\n",
    "Model Description:\n",
    "Next, we experiment with a Support Vector Machine (SVM). The SVM is a powerful classifier, especially effective in high-dimensional spaces, such as the feature space generated by text data.\n",
    "\n",
    "Why This Model:\n",
    "SVMs are known for their ability to find optimal decision boundaries in high-dimensional data. By using the linear kernel, we expect SVM to capture complex patterns within the data, potentially improving upon the Random Forest model.\n",
    "\n",
    "#### Evaluation\n",
    "We evaluated the SVM model and compared its performance against both Logistic Regression and Random Forest models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjbY1ZojQ580",
    "outputId": "128eeff3-30b4-4487-f77e-1d64b72b81fb"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the Support Vector Machine model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, svm_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQ08Pl9KRFaj"
   },
   "source": [
    "##4. Final Model: XGBoost\n",
    "Model Description:\n",
    "Finally, we try XGBoost (Extreme Gradient Boosting). XGBoost is a state-of-the-art ensemble method that has been shown to perform exceptionally well on various classification tasks, particularly when handling structured data.\n",
    "\n",
    "Why This Model:\n",
    "XGBoost uses boosting, which combines weak learners (shallow trees) to create a strong learner. It is known for its high performance, particularly on imbalanced datasets, and is expected to further improve classification accuracy over previous models.\n",
    "\n",
    "#### Evaluation\n",
    "We assessed the performance of XGBoost and compared it with the previous models (Logistic Regression, Random Forest, and SVM). This allowed us to analyze the impact of this more sophisticated technique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gkrk2TdkRCbE",
    "outputId": "fb959810-3d2a-415b-d0fc-9f00dd926b5b"
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z4kA1tSVR9oD"
   },
   "source": [
    "##Improvement Analysis\n",
    "\n",
    "### Final Model: Performance Comparison and Justification\n",
    "By comparing the results of each model (Logistic Regression, Random Forest, SVM, and XGBoost), we can observe the progression in terms of accuracy and F1-score. Based on these comparisons, the model with the best performance will be selected for final evaluation and interpretation.\n",
    "\n",
    "### Next Steps: Addressing Class Imbalance\n",
    "To improve the model further, especially for the minority classes, we will address the **class imbal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUyeqpa4SukM"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToU_WFlaSwx9"
   },
   "source": [
    "### Final Model Selection\n",
    "\n",
    "After comparing the performance of several models (Logistic Regression, Random Forest, SVM, and XGBoost), we select **Logistic Regression** as the final model. This model was chosen because:\n",
    "\n",
    "- **Accuracy**: Logistic Regression achieved an accuracy of **0.7391**, which is the highest among the models tested.\n",
    "- **Class Imbalance**: Although Logistic Regression struggles with class 3, it performs well on the majority of classes (especially class 1, with high recall).\n",
    "- **Model Simplicity**: Logistic Regression is a relatively simple model, making it easier to interpret and deploy in real-world applications.\n",
    "\n",
    "Given the importance of balancing performance across classes, **Logistic Regression** is the best choice for our final model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDHUQC2tS4to"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-3EQUTyS6lj"
   },
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "For evaluating the final **Logistic Regression** model, we focus on the following metrics:\n",
    "\n",
    "- **Accuracy**: While useful, accuracy alone does not provide enough insight when there is class imbalance. However, it still offers a general overview of model performance.\n",
    "  \n",
    "- **Precision and Recall**: Given the class imbalance, we pay special attention to precision and recall for each class. This ensures that the model doesn't overly favor the majority class and performs well across all accident causes.\n",
    "\n",
    "- **F1-Score**: The F1-score balances precision and recall, which is important for this problem where both false positives and false negatives have real-world implications.\n",
    "\n",
    "- **Confusion Matrix**: The confusion matrix helps us understand where the model is making errors (which classes are being misclassified) and is valuable for identifying areas for improvement.\n",
    "\n",
    "These metrics were chosen based on the need to ensure that the model performs well across all accident causes and minimizes misclassification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJapV4OATHA1"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvJV7c-MTICk"
   },
   "source": [
    "### Interpreting the Evaluation Results\n",
    "\n",
    "The **Logistic Regression** model was evaluated using accuracy, precision, recall, F1-score, and the confusion matrix. Below is a summary of the results and their implications:\n",
    "\n",
    "- **Accuracy**: The model achieved an accuracy of 74%, indicating that it correctly predicted most of the instances. However, due to class imbalance, this metric doesn't fully capture the model's performance.\n",
    "  \n",
    "- **Precision and Recall**:\n",
    "  - **Class 0**: The model correctly identified 66% of instances (Recall) but had a high precision of 79%. This means the model is fairly accurate in predicting this class.\n",
    "  - **Class 1**: The model performs well in terms of recall (94%), indicating it identifies most of the instances of this class, though precision could be improved (71%).\n",
    "  - **Class 2**: The model struggles with Class 2, having a high precision (87%) but a low recall (20%). This suggests that many instances of Class 2 are missed.\n",
    "  - **Class 3**: The model fails to detect any instances of this class (precision and recall are both 0.00), likely due to the low number of samples.\n",
    "\n",
    "- **F1-Score**: The F1-score for Class 1 is the highest (0.81), while the score for Class 3 is 0.00, indicating the model's inability to detect this class.\n",
    "\n",
    "#### Real-World Implications:\n",
    "- **Class Imbalance**: The modelâ€™s failure to predict rare accident causes (Class 2 and Class 3) could lead to missed opportunities for improving safety measures. Addressing this issue is crucial for real-world applications.\n",
    "- **Refinement Needed**: The model could benefit from techniques such as oversampling, undersampling, or the use of synthetic data to improve performance on underrepresented classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8PBq4YWTOJ8"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tV3epMeATPDN"
   },
   "source": [
    "### Discussing the Implications for the Real-World Problem\n",
    "\n",
    "In the context of predicting the primary contributory cause of car accidents, the evaluation results have important real-world implications. These include:\n",
    "\n",
    "- **Class Imbalance**:\n",
    "  - The model performs well on the majority class (Class 1), but it struggles with the minority classes (Class 2 and Class 3). In the real world, this could be problematic because accident causes that are less common (but potentially more dangerous) are not being identified effectively.\n",
    "  - If the rare causes of accidents are not detected, crucial safety measures may not be implemented, leading to unaddressed risks.\n",
    "\n",
    "- **Modelâ€™s Utility**:\n",
    "  - Although the model provides decent predictions for Class 0 and Class 1 (which might represent more common causes of accidents), its failure to predict Class 2 and Class 3 correctly highlights the need for improvement. This failure limits the modelâ€™s utility in real-world applications.\n",
    "  - For example, if Class 3 represents a rare yet critical accident cause (e.g., mechanical failure), not predicting this can be costly and could lead to safety risks for drivers.\n",
    "\n",
    "- **Improvement Potential**:\n",
    "  - Given the importance of predicting all accident causes accurately, improving performance on Class 2 and Class 3 should be a priority. Techniques such as oversampling, undersampling, or using synthetic data generation (e.g., SMOTE) could help balance the dataset and improve predictions for rare classes.\n",
    "  - Another possible improvement is adjusting class weights to give more importance to the minority classes during model training.\n",
    "\n",
    "- **Real-World Application**:\n",
    "  - For stakeholders like vehicle safety boards or city authorities, the modelâ€™s current inability to predict certain accident causes accurately could hinder efforts to improve road safety. However, the model could still be useful in identifying the most common causes and providing insights into accident trends.\n",
    "  - The implications of misclassifying rare causes may not be immediately apparent, but over time, if safety improvements aren't made based on accurate predictions, the consequences could include increased accident rates or undetected risks.\n",
    "\n",
    "---\n",
    "\n",
    "By identifying these challenges, we can take the necessary steps to improve the model's robustness and make it more suitable for real-world use.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ne_em-RGTQcA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFz5BrgRTRdb"
   },
   "source": [
    "### Step 5: Discussing Next Steps\n",
    "\n",
    "Based on the evaluation of the modelâ€™s performance and its limitations, there are several steps we can take to improve the model and its real-world application:\n",
    "\n",
    "#### 1. **Handling Class Imbalance**\n",
    "   - **Oversampling Minority Classes**: By using oversampling techniques like SMOTE (Synthetic Minority Over-sampling Technique), we can generate synthetic samples for the underrepresented classes (such as Class 2 and Class 3). This will help balance the dataset and improve the modelâ€™s ability to predict minority classes.\n",
    "   - **Undersampling Majority Class**: Another approach would be to undersample the majority class (Class 1). This may reduce the bias towards predicting the majority class and improve performance across all classes.\n",
    "   - **Class Weight Adjustment**: Adjusting the class weights during training to make the model pay more attention to the minority classes could also help improve accuracy for these classes.\n",
    "\n",
    "#### 2. **Model Improvement Techniques**\n",
    "   - **Hyperparameter Tuning**: Further optimization of the modelâ€™s hyperparameters (e.g., regularization strength, learning rate, etc.) could lead to better generalization on the test data. Using techniques like grid search or randomized search can help find the best combination of parameters.\n",
    "   - **Ensemble Methods**: Implementing ensemble methods such as Random Forests or XGBoost can enhance prediction accuracy by combining multiple weak models to form a stronger predictive model.\n",
    "   - **Model Interpretability**: Since the goal is to understand the factors contributing to car accidents, implementing tools like SHAP (Shapley Additive Explanations) could help provide insights into why the model is making certain predictions. This will be useful for stakeholders when making decisions based on the model.\n",
    "\n",
    "#### 3. **Addressing Rare Classes in the Data**\n",
    "   - **Anomaly Detection**: For rare accident causes that might not have enough data, applying anomaly detection algorithms could help identify rare but significant accident causes that don't fit the general patterns.\n",
    "   - **Improving Data Collection**: To improve the modelâ€™s performance on rare classes, additional data could be collected, especially for underrepresented accident causes. This would give the model more examples to learn from.\n",
    "\n",
    "#### 4. **Deployment Considerations**\n",
    "   - **Model Monitoring**: Once the model is deployed, itâ€™s crucial to continuously monitor its performance. If the model starts to degrade in accuracy, retraining with updated data or adjusting the model might be necessary.\n",
    "   - **Real-Time Predictions**: If the model is to be used in real-time applications, such as predicting accident causes as incidents occur, we should consider using faster models or reducing the computational complexity without compromising too much on accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "By taking these steps, we can further refine the model and make it more effective for solving the real-world problem of accident cause prediction. It will help authorities make informed decisions to improve road safety and prevent accidents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eyirpAs0UP8C"
   },
   "source": [
    "The final evaluation results are as follows:\n",
    "\n",
    "Accuracy:\n",
    "0.7391: This indicates that the model correctly predicted approximately 73.91% of the test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-deP1cNSAsE",
    "outputId": "1215b0bc-4f04-4f2a-b15c-e14c4803dc67"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "# Assuming the baseline model was Logistic Regression and it performed well, we use it as the final model\n",
    "final_model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the final model on the training data\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the final model on the test data\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "final_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Classification report\n",
    "classification_rep = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "final_accuracy, classification_rep, conf_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bkrqq1kXUcUg"
   },
   "source": [
    "### Implications of Final Model Evaluation for Solving the Real-World Problem\n",
    "\n",
    "The evaluation of the final model, Logistic Regression, reveals several insights that have implications for how well the model can address the real-world problem of predicting the primary contributory cause of a car accident in Chicago:\n",
    "\n",
    "#### 1. **Class Imbalance Impact**\n",
    "   - The model struggles with **class imbalance**, especially with the minority class (class 3), which has very few samples. This leads to poor performance (precision, recall, and F1-score) for this class, indicating that the model is not effectively identifying it.\n",
    "   - **Real-World Implication:** Predicting rare events like certain types of car accidents (represented by class 3) is crucial, but the current modelâ€™s inability to accurately predict these events limits its utility in real-world applications, such as traffic safety analysis or vehicle safety policy-making.\n",
    "\n",
    "#### 2. **Accuracy vs. Specificity**\n",
    "   - While the model achieves a decent **accuracy** of ~73.91%, this metric doesnâ€™t fully reflect the performance across all classes, especially the minority classes. The **recall** for class 3 is 0%, indicating that the model is not identifying accidents where this class is the primary cause.\n",
    "   - **Real-World Implication:** In the context of vehicle safety, failure to predict certain types of accidents could have significant consequences for safety improvements. For example, if a certain cause (class 3) leads to high-risk accidents but is misclassified, safety interventions could be misguided.\n",
    "\n",
    "#### 3. **Precision and Recall for Major Classes**\n",
    "   - For the major classes (0 and 1), precision and recall scores are relatively high, indicating that the model is performing well for these classes.\n",
    "   - **Real-World Implication:** For common accident causes (classes 0 and 1), the model provides reasonable predictions, which can help in developing general safety policies, interventions, or insurance strategies. However, focusing only on these major causes could leave critical safety concerns unaddressed.\n",
    "\n",
    "#### 4. **Improvement Potential**\n",
    "   - The model's inability to predict class 3 and limited performance for class 2 shows that there is room for significant improvement, both in terms of balancing the class distribution and enhancing the model's capability to detect rare events.\n",
    "   - **Real-World Implication:** The current modelâ€™s utility is restricted, as it might miss key accident causes that have long-term consequences for policy formulation. A better model, possibly using class balancing techniques or more complex models, could provide more reliable predictions for all classes.\n",
    "\n",
    "#### 5. **Model Robustness**\n",
    "   - The fact that the Logistic Regression model's results vary significantly across classes suggests that further improvements in model robustness are needed to ensure that it generalizes well across all accident types.\n",
    "   - **Real-World Implication:** If the model continues to perform inconsistently, it could undermine its reliability in real-world scenarios. More robust models, including ensemble methods or techniques like SMOTE for handling class imbalance, could address these gaps and improve predictions.\n",
    "\n",
    "#### Conclusion\n",
    "The evaluation suggests that while the Logistic Regression model performs reasonably well for some accident causes, it still faces challenges in handling rare events and ensuring consistent predictions across all classes. Future improvements could involve addressing class imbalance, experimenting with other models, and using more sophisticated techniques to enhance its applicability in real-world vehicle safety and accident analysis.\n",
    "\n",
    "The model is not showing strong signs of underfitting or overfitting. The accuracy and other metrics are fairly reasonable, but the poor performance on class 3 suggests that class imbalance might be affecting the modelâ€™s ability to generalize well across all categories.\n",
    "\n",
    "To improve model performance, you can:\n",
    "\n",
    "Handle class imbalance (e.g., using SMOTE or class weighting).\n",
    "\n",
    "Try more complex models or ensemble methods to better capture minority class patterns.\n",
    "\n",
    "Perform hyperparameter tuning to ensure the model is well-optimized for both bias and variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAMtah3qTv0V"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
