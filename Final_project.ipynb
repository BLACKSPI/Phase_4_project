{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExMN0Dq1J93s"
   },
   "source": [
    "# Final Project.\n",
    "We shal use the capstone guideline for this project:\n",
    "1. Business Problem.\n",
    "2. Data Understanding\n",
    "3. Data Preparation.\n",
    "4. Modelling\n",
    "5. Evaluation\n",
    "\n",
    "\n",
    "# Business Understanding\n",
    "\n",
    "## 1. Introduction:\n",
    "This modern age, social media platforms like Twitter act as  major sources for public opinions and feedback. Companies like **Apple**, understanding how customers perceive their products on Twitter is crucial for improving product development, marketing strategies, and customer relationships.\n",
    "\n",
    "So manually analyzing thousands of tweets to understand sentiment is an insane task so to speak. **Natural Language Processing (NLP)** can automate this process.\n",
    "\n",
    "The goal of this project is to develop  **NLP model** that can automatically classify the sentiment of a tweet as **positive**, **negative**, or **neutral**. This will help Apple and other stakeholders make informed decisions based on public sentiment.\n",
    "\n",
    "## 2. Stakeholders\n",
    "The stakeholders who gain from this analysis model:\n",
    "\n",
    "1.\n",
    "- **Apple and other tech companies**:\n",
    "   - **Marketing Teams**: Can use the model to track customer reactions to marketing campaigns, product launches, and other brand activities.\n",
    "   - **Product Development Teams**: Can identify which features are well-received and which need improvement based on real-time public sentiment.\n",
    "\n",
    "2.\n",
    "- **Customers**:\n",
    "   - Customers can see how their opinions are reflected in public sentiment trends, and how other users feel about Apple products.\n",
    "\n",
    "- **Competitors **:\n",
    "   - Competitors can analyze sentiment around Apple products to gain insights into Apple's strengths and weaknesses, guiding their own product strategies.\n",
    "\n",
    "## 3. Advantage of project for staeholders:\n",
    "The sentiment analysis model will provide the following benefits to stakeholders:\n",
    "- **Apple**:\n",
    "   - Helps monitor real-time public sentiment about Apple products giving faster response to customer feedback.\n",
    "- **Marketing Teams**:\n",
    "   - Allows for the measurement of campaign effectiveness and helps adjust marketing strategies based on sentiment.\n",
    "\n",
    "## 4. Implications for the Real-World Problem\n",
    "By automating sentiment analysis on Twitter, Apple and other stakeholders can gain valuable insights without the need for extensive manual work. The ability to track public sentiment in real-time means that Apple can be more responsive to customer feedback, optimize marketing efforts, and improve product offerings. This can ultimately lead to more successful product launches and higher customer satisfaction.\n",
    "\n",
    "## 5. Business Value Summary\n",
    "This NLP sentiment analysis model provides actionable insights that will help Apple make informed business decisions quickly and efficiently. By understanding public sentiment, Apple can enhance customer engagement, drive product innovation, and maintain a competitive edge in the market.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dt9jf1qTKIFu"
   },
   "source": [
    "# Data Understanding\n",
    "\n",
    "## 1. Data Source\n",
    "The dataset used for this project is **CrowdFlower**, on **data.world**. The dataset has a lot of tweets that have been manually rated for sentiment by human annotators. Each tweet is labeled with one of three sentiment categories: **positive**, **negative**, or **neutral**.\n",
    "\n",
    "## 2. Dataset Size and Descriptive Statistics\n",
    "The dataset consists of over 5,000 tweets with the following key features:\n",
    "\n",
    "- **Tweet**: The textual content of the tweet (string).\n",
    "- **Sentiment**: The sentiment label assigned to each tweet (categorical: Positive, Negative, Neutral).\n",
    "  \n",
    "### Descriptive Statistics:\n",
    "Some basic statistics:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0rNAirHKQyj"
   },
   "source": [
    "\n",
    "- **The size and structure** of the dataset with basic descriptive statistics and an initial look at sentiment distribution.\n",
    "- **Limitations** of the data that may impact model performance, such as class imbalance or labeling biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hl3BE7rBLGXs"
   },
   "source": [
    "1. Loading the Dataset is essential for this project first. This allows us to use the notebook to understand the statistics of the datasource and clean it further.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p5gAPv3pJDv4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YrXs2O-MKULt"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Apple-Twitter-Sentiment-DFE.csv', encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "Y8cUS-6SKcxT",
    "outputId": "b7512b13-c5f0-4b49-9b0b-16275581ea13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_unit_id</th>\n",
       "      <th>_golden</th>\n",
       "      <th>_unit_state</th>\n",
       "      <th>_trusted_judgments</th>\n",
       "      <th>_last_judgment_at</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment:confidence</th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>query</th>\n",
       "      <th>sentiment_gold</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>623495513</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6264</td>\n",
       "      <td>Mon Dec 01 19:30:03 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\nnot_relevant</td>\n",
       "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623495514</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8129</td>\n",
       "      <td>Mon Dec 01 19:43:51 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>623495515</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Mon Dec 01 19:50:28 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3</td>\n",
       "      <td>My cat only chews @apple cords. Such an #Apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>623495516</td>\n",
       "      <td>True</td>\n",
       "      <td>golden</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5848</td>\n",
       "      <td>Mon Dec 01 20:26:34 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>3\\n1</td>\n",
       "      <td>I agree with @jimcramer that the #IndividualIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>623495517</td>\n",
       "      <td>False</td>\n",
       "      <td>finalized</td>\n",
       "      <td>3</td>\n",
       "      <td>12/12/14 12:14</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6474</td>\n",
       "      <td>Mon Dec 01 20:29:33 +0000 2014</td>\n",
       "      <td>5.400000e+17</td>\n",
       "      <td>#AAPL OR @Apple</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nobody expects the Spanish Inquisition #AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    _unit_id  _golden _unit_state  _trusted_judgments _last_judgment_at  \\\n",
       "0  623495513     True      golden                  10               NaN   \n",
       "1  623495514     True      golden                  12               NaN   \n",
       "2  623495515     True      golden                  10               NaN   \n",
       "3  623495516     True      golden                  17               NaN   \n",
       "4  623495517    False   finalized                   3    12/12/14 12:14   \n",
       "\n",
       "  sentiment  sentiment:confidence                            date  \\\n",
       "0         3                0.6264  Mon Dec 01 19:30:03 +0000 2014   \n",
       "1         3                0.8129  Mon Dec 01 19:43:51 +0000 2014   \n",
       "2         3                1.0000  Mon Dec 01 19:50:28 +0000 2014   \n",
       "3         3                0.5848  Mon Dec 01 20:26:34 +0000 2014   \n",
       "4         3                0.6474  Mon Dec 01 20:29:33 +0000 2014   \n",
       "\n",
       "             id            query   sentiment_gold  \\\n",
       "0  5.400000e+17  #AAPL OR @Apple  3\\nnot_relevant   \n",
       "1  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "2  5.400000e+17  #AAPL OR @Apple                3   \n",
       "3  5.400000e+17  #AAPL OR @Apple             3\\n1   \n",
       "4  5.400000e+17  #AAPL OR @Apple              NaN   \n",
       "\n",
       "                                                text  \n",
       "0  #AAPL:The 10 best Steve Jobs emails ever...htt...  \n",
       "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...  \n",
       "2  My cat only chews @apple cords. Such an #Apple...  \n",
       "3  I agree with @jimcramer that the #IndividualIn...  \n",
       "4       Nobody expects the Spanish Inquisition #AAPL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B5SFb5wOKmSc",
    "outputId": "a7576e9f-0e88-4b2f-eb4c-ab7d4e01c88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (3886, 12)\n",
      "Columns in dataset: Index(['_unit_id', '_golden', '_unit_state', '_trusted_judgments',\n",
      "       '_last_judgment_at', 'sentiment', 'sentiment:confidence', 'date', 'id',\n",
      "       'query', 'sentiment_gold', 'text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset's shape and column names\n",
    "print(f\"Shape of dataset: {df.shape}\")\n",
    "print(f\"Columns in dataset: {df.columns}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kklFFXQWLUab"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBpPeG60LWxD"
   },
   "source": [
    "Removing Unnecessary Columns\n",
    "\n",
    "Objective: Remove irrelevant columns that won't be used for analysis, making the dataset cleaner and more focused.\n",
    "\n",
    "Justification:\n",
    "\n",
    "Irrelevant columns: These columns provide metadata or details that do not contribute to the sentiment analysis model. Removing them streamlines the dataset and improves processing speed.\n",
    "\n",
    "By dropping columns such as id, query, and _unit_id, we focus only on the features that matter: the tweet text and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "bFHmkuqSK93D",
    "outputId": "47f4d517-bf11-41d3-fa7f-7ba8f4f71bcd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>#AAPL:The 10 best Steve Jobs emails ever...htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>My cat only chews @apple cords. Such an #Apple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I agree with @jimcramer that the #IndividualIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Nobody expects the Spanish Inquisition #AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text\n",
       "0         3  #AAPL:The 10 best Steve Jobs emails ever...htt...\n",
       "1         3  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...\n",
       "2         3  My cat only chews @apple cords. Such an #Apple...\n",
       "3         3  I agree with @jimcramer that the #IndividualIn...\n",
       "4         3       Nobody expects the Spanish Inquisition #AAPL"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns that are not useful for analysis\n",
    "df.drop(columns=['_unit_id', '_golden', '_unit_state', '_trusted_judgments', '_last_judgment_at', 'sentiment:confidence', 'date', 'id', 'query', 'sentiment_gold'], inplace=True)\n",
    "\n",
    "# Verify the changes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TLf5wFVLjak"
   },
   "source": [
    "# Handling Missing Data\n",
    "We need to Identify and handle any missing values in the dataset. Missing data can impact model performance, so we either drop or impute it based on the context.\n",
    "\n",
    "Incase the tweet text or sentiment is missing, the data is incomplete and can't be used for analysis. Hence, we drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "id": "c-b9-IkQLZw8",
    "outputId": "ad35c6b5-d0cc-47b8-fa84-b3d68b4af3dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "# Drop rows with missing text or sentiment labels\n",
    "df.dropna(subset=['text', 'sentiment'], inplace=True)\n",
    "\n",
    "# Verify that there are no missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixekb13JLotc"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aSBQxEm4LrVL"
   },
   "source": [
    "## Encoding  Labels\n",
    "\n",
    "We need to Convert the sentiment labels (positive, negative, neutral) into numerical values so they can be used by machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vo4KXdbRL2Y7"
   },
   "source": [
    "Label Encoding: Machine learning models can only work with numerical data. Encoding the categorical sentiment labels ensures the model can process them.\n",
    "\n",
    "This is an essential step as the analysis is a classification job. Label encoding converts categories (positive, negative, neutral) into numerical labels (0, 1, 2), making them ready for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "45AgzpJnLlnr",
    "outputId": "81806b76-d355-4945-9715-0d09715d9305"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2162\n",
       "0    1219\n",
       "2     423\n",
       "3      82\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Encode the sentiment labels\n",
    "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Verify the encoding\n",
    "df['sentiment'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zxnPxZQ2L5cj"
   },
   "source": [
    "## Text Preprocessing\n",
    "Objective: Clean the text data to ensure it is in a format that can be processed by the machine learning model. This includes removing special characters, stop words, and unnecessary spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWltmhrYLxtE",
    "outputId": "38d117b8-322a-4de7-da0c-07c6057ae2c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Download the stopwords resource\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3sbslCPMU-L",
    "outputId": "3111d91e-f48b-4dfb-ea45-6a1bcd7e24d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OKOEi4ZHL8mU",
    "outputId": "3eec39a5-8944-4992-813f-83179518dccd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Return cleaned text as a string\n",
    "    return ' '.join(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZk7ZckuNJqT"
   },
   "source": [
    "Feature Engineering\n",
    "\n",
    "We Convert the cleaned text into a numerical format that machine learning models can understand. We'll use TF-IDF for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Hhg2rHVMn7F",
    "outputId": "842d2b76-c747-48e7-9c38-ca63b79209ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3886, 5000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initialize the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)  # Limit to 5000 features to avoid overfitting\n",
    "\n",
    "# Fit and transform the 'text' column\n",
    "X = vectorizer.fit_transform(df['text']).toarray()\n",
    "\n",
    "# Verify the shape of the feature matrix\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W1is4i02OBHr",
    "outputId": "32f90a76-c2b2-4d04-a886-9fa0f680c510"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sentiment', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the column names of your dataframe\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BhcsZOdOOluU",
    "outputId": "d4c1bf92-03c5-414c-de64-3fc308956de5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4eBDxOtOtTk",
    "outputId": "0b54ceb6-9c65-4818-c47f-4c3535782b6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\User/nltk_data', 'C:\\\\Users\\\\User\\\\anaconda3\\\\envs\\\\learn-env\\\\nltk_data', 'C:\\\\Users\\\\User\\\\anaconda3\\\\envs\\\\learn-env\\\\share\\\\nltk_data', 'C:\\\\Users\\\\User\\\\anaconda3\\\\envs\\\\learn-env\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.data.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DxtUM8dZO15T"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.data.path.append('/root/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G4naZGq4O3D8",
    "outputId": "acc035b0-af0e-4d0a-ba80-c78986115068"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KXQtzM35O5NM",
    "outputId": "d7eef131-af1e-4c47-f27a-0c8af78185fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2Y0H2dVPGtJ",
    "outputId": "339e01f4-9091-46b2-f7a3-6e603f52f47e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "He_DA4tlPKN9"
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zU1ADVDYPNPE",
    "outputId": "1f9de7e5-9fc8-4f9c-e1d9-d0136714d6ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Punkt tokenizer is available!\n"
     ]
    }
   ],
   "source": [
    "# Check if 'punkt' is available\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "try:\n",
    "    word_tokenize(\"This is a test sentence.\")\n",
    "    print(\"Punkt tokenizer is available!\")\n",
    "except LookupError as e:\n",
    "    print(\"Error: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HkabNohdOHuj",
    "outputId": "c46b1933-2c8b-4562-865b-75b4c57273bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  \\\n",
      "0  #AAPL:The 10 best Steve Jobs emails ever...htt...   \n",
      "1  RT @JPDesloges: Why AAPL Stock Had a Mini-Flas...   \n",
      "2  My cat only chews @apple cords. Such an #Apple...   \n",
      "3  I agree with @jimcramer that the #IndividualIn...   \n",
      "4       Nobody expects the Spanish Inquisition #AAPL   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0                aaplthe best steve jobs emails ever  \n",
      "1  rt jpdesloges aapl stock miniflash crash today...  \n",
      "2                    cat chews apple cords applesnob  \n",
      "3  agree jimcramer individualinvestor trade apple...  \n",
      "4            nobody expects spanish inquisition aapl  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download necessary NLTK resources if you haven't already\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "\n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    # Return cleaned text as a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply the cleaning function to the 'text' column to create 'cleaned_text'\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Verify the first few rows to ensure 'cleaned_text' is created\n",
    "print(df[['text', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B_WS8LO1NlqL"
   },
   "source": [
    "Visualizations part of EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "58ASEderNp_L"
   },
   "source": [
    "## Class Distribution (Sentiment Distribution)\n",
    "Bar Plot to show the distribution of sentiments in your dataset (e.g., how many positive, negative, and neutral sentiments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "Y3pPPihTNLy0",
    "outputId": "c73ea491-aab5-4756-9796-58dc663b6983"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot sentiment distribution\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='sentiment', data=df)\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9p1ke4dNwAT"
   },
   "source": [
    "# Word Cloud for Most Frequent Terms\n",
    "Visualize the most common words in your dataset, which can give you an idea of the frequent terms in the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsP0FFLRPgok",
    "outputId": "31ece707-29d5-4d60-886f-b776ad1120d4"
   },
   "outputs": [],
   "source": [
    "!pip uninstall pillow wordcloud\n",
    "!pip install pillow wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "zxK9F1r6Nt0U",
    "outputId": "304b39eb-177a-4bfa-f81a-65779825d0dc"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot open resource",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-f8de9e61cb58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Generate word cloud with a TrueType font\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m wordcloud = WordCloud(\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"./fonts/Roboto-Regular.ttf\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \"\"\"\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    622\u001b[0m         \"\"\"\n\u001b[0;32m    623\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mfont_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 self.generate_from_frequencies(dict(frequencies[:2]),\n\u001b[0m\u001b[0;32m    454\u001b[0m                                                max_font_size=self.height)\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# find font sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    504\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m                 \u001b[1;31m# try to find a position\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m                 \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtruetype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfont_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m                 \u001b[1;31m# transpose font optionally\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                 transposed_font = ImageFont.TransposedFont(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\PIL\\ImageFont.py\u001b[0m in \u001b[0;36mtruetype\u001b[1;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 844\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\PIL\\ImageFont.py\u001b[0m in \u001b[0;36mfreetype\u001b[1;34m(font)\u001b[0m\n\u001b[0;32m    839\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfreetype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFreeTypeFont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\PIL\\ImageFont.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[0;32m    191\u001b[0m                         \u001b[0mload_from_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m                     \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m             self.font = core.getfont(\n\u001b[0m\u001b[0;32m    194\u001b[0m                 \u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout_engine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayout_engine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             )\n",
      "\u001b[1;31mOSError\u001b[0m: cannot open resource"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Combine all cleaned text into a single string\n",
    "all_text = ' '.join(df['cleaned_text'])\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_text)\n",
    "\n",
    "# Plot the word cloud\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')  # Turn off axis\n",
    "plt.title('Most Frequent Words in the Tweets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xyigpVgXPpZc"
   },
   "source": [
    "## Top Positive and Negative Words\n",
    "You can visualize the most frequent words in positive and negative sentiment categories. Here's a quick way to extract and plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0edGuD5TNzyc",
    "outputId": "8cce4414-e1da-4ec2-b0a1-9edbaa32bb96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    2162\n",
      "0    1219\n",
      "2     423\n",
      "3      82\n",
      "Name: sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "uQ4i7hGpPsjl"
   },
   "outputs": [],
   "source": [
    "#filter for positive and negative tweets\n",
    "positive_tweets = df[df['sentiment'] == 1]\n",
    "negative_tweets = df[df['sentiment'] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "nZX7VrUDP9Kz"
   },
   "outputs": [],
   "source": [
    "#Ectract text for generation\n",
    "positive_text = ' '.join(positive_tweets['cleaned_text'])\n",
    "negative_text = ' '.join(negative_tweets['cleaned_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "jYV-4YxEQC0E",
    "outputId": "10331e1d-8608-41c1-e8b1-0d3be2066841"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Only supported for TrueType fonts",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-983e52c73b75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Generate word clouds for both positive and negative sentiments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpositive_wordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositive_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mnegative_wordcloud\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m800\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackground_color\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'white'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnegative_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \"\"\"\n\u001b[1;32m--> 642\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    622\u001b[0m         \"\"\"\n\u001b[0;32m    623\u001b[0m         \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    451\u001b[0m                 \u001b[0mfont_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                 self.generate_from_frequencies(dict(frequencies[:2]),\n\u001b[0m\u001b[0;32m    454\u001b[0m                                                max_font_size=self.height)\n\u001b[0;32m    455\u001b[0m                 \u001b[1;31m# find font sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\wordcloud\\wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_frequencies\u001b[1;34m(self, frequencies, max_font_size)\u001b[0m\n\u001b[0;32m    509\u001b[0m                     font, orientation=orientation)\n\u001b[0;32m    510\u001b[0m                 \u001b[1;31m# get size of resulting text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                 \u001b[0mbox_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtextbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransposed_font\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manchor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m                 \u001b[1;31m# find possible places using integral image:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m                 result = occupancy.sample_position(box_size[3] + self.margin,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\PIL\\ImageDraw.py\u001b[0m in \u001b[0;36mtextbbox\u001b[1;34m(self, xy, text, font, anchor, spacing, align, direction, features, language, stroke_width, embedded_color)\u001b[0m\n\u001b[0;32m    669\u001b[0m             \u001b[0mfont\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetfont\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfont\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFont\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreeTypeFont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 671\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Only supported for TrueType fonts\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    672\u001b[0m         \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"RGBA\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0membedded_color\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfontmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m         bbox = font.getbbox(\n",
      "\u001b[1;31mValueError\u001b[0m: Only supported for TrueType fonts"
     ]
    }
   ],
   "source": [
    "#Generate worldcloud plot\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate word clouds for both positive and negative sentiments\n",
    "positive_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(positive_text)\n",
    "negative_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(negative_text)\n",
    "\n",
    "# Plot the word clouds\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(positive_wordcloud, interpolation='bilinear')\n",
    "plt.title(\"Positive Sentiment\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(negative_wordcloud, interpolation='bilinear')\n",
    "plt.title(\"Negative Sentiment\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Iug9z4UQVki"
   },
   "source": [
    "##**Modeling**\n",
    "In this section, we will build multiple models iteratively, starting from a simple baseline model and progressively adding more complexity. We will compare the performance of each model and justify the improvements over the previous ones based on the results. The goal is to demonstrate an effective approach to model-building, starting from a basic model and moving toward more advanced techniques.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vR8PrFNFQo7c",
    "outputId": "6ce19297-3f39-4f2f-e945-87fd1dbee105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3108, 5000) (778, 5000)\n"
     ]
    }
   ],
   "source": [
    "#Train and test splits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X' is the feature matrix (TF-IDF features) and 'y' is the target variable (sentiment)\n",
    "X = vectorizer.transform(df['cleaned_text']).toarray()  # Or you can use the vectorized version from earlier\n",
    "y = df['sentiment']  # Target variable\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the shape of the training and test sets\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5c-zh6DQcUU"
   },
   "source": [
    "##1. Baseline Model: Logistic Regression\n",
    "Model Description:\n",
    "We begin by training a Logistic Regression model as our baseline. Logistic Regression is a simple yet effective model for binary classification tasks. It will provide us with an initial benchmark to compare more complex models against.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b5jTmVI_QHMc",
    "outputId": "6e86e126-072c-46e1-de7e-9e32ef6b94fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy: 0.7391\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.65      0.72       240\n",
      "           1       0.71      0.94      0.81       424\n",
      "           2       0.80      0.20      0.32        99\n",
      "           3       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.74       778\n",
      "   macro avg       0.58      0.45      0.46       778\n",
      "weighted avg       0.74      0.74      0.71       778\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\User\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Initialize and train the baseline Logistic Regression model\n",
    "baseline_model = LogisticRegression(max_iter=1000)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "baseline_y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "baseline_accuracy = accuracy_score(y_test, baseline_y_pred)\n",
    "print(f\"Baseline Accuracy: {baseline_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, baseline_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PedTdC8QQ3Hd"
   },
   "source": [
    "##2. Improved Model: Random Forest Classifier\n",
    "Model Description:\n",
    "To improve upon the baseline Logistic Regression model, we introduce a Random Forest Classifier. Random Forest is an ensemble method that builds multiple decision trees and combines their results to improve prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHCPc1TjQiqU",
    "outputId": "57a83537-c161-4e27-9917-f439c4f852fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7237\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.59      0.68       240\n",
      "           1       0.70      0.94      0.80       424\n",
      "           2       0.65      0.24      0.35        99\n",
      "           3       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.72       778\n",
      "   macro avg       0.54      0.44      0.46       778\n",
      "weighted avg       0.72      0.72      0.69       778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)\n",
    "print(f\"Random Forest Accuracy: {rf_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, rf_y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY3WVgUgQ_AT"
   },
   "source": [
    "##3. Further Improvement: Support Vector Machine (SVM)\n",
    "Model Description:\n",
    "Next, we experiment with a Support Vector Machine (SVM). The SVM is a powerful classifier, especially effective in high-dimensional spaces, such as the feature space generated by text data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjbY1ZojQ580",
    "outputId": "128eeff3-30b4-4487-f77e-1d64b72b81fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7314\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.65      0.70       240\n",
      "           1       0.72      0.92      0.80       424\n",
      "           2       0.78      0.25      0.38        99\n",
      "           3       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.73       778\n",
      "   macro avg       0.57      0.45      0.47       778\n",
      "weighted avg       0.73      0.73      0.70       778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the Support Vector Machine model\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "svm_accuracy = accuracy_score(y_test, svm_y_pred)\n",
    "print(f\"SVM Accuracy: {svm_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, svm_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gkrk2TdkRCbE",
    "outputId": "fb959810-3d2a-415b-d0fc-9f00dd926b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7159\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.56      0.66       240\n",
      "           1       0.70      0.93      0.80       424\n",
      "           2       0.62      0.29      0.40        99\n",
      "           3       0.00      0.00      0.00        15\n",
      "\n",
      "    accuracy                           0.72       778\n",
      "   macro avg       0.53      0.45      0.46       778\n",
      "weighted avg       0.71      0.72      0.69       778\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "xgb_y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "xgb_accuracy = accuracy_score(y_test, xgb_y_pred)\n",
    "print(f\"XGBoost Accuracy: {xgb_accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, xgb_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-deP1cNSAsE",
    "outputId": "1215b0bc-4f04-4f2a-b15c-e14c4803dc67"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[156,  81,   3,   0],\n",
       "       [ 23, 399,   2,   0],\n",
       "       [ 13,  66,  20,   0],\n",
       "       [  2,  13,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "final_accuracy\n",
    "classification_rep\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define hyperparameter grids for each model\n",
    "param_grids = {\n",
    "    \"Logistic Regression\": {\n",
    "        \"C\": [0.01, 0.1, 1, 10, 100],\n",
    "        \"solver\": [\"liblinear\", \"lbfgs\"]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [10, 20, 30],\n",
    "        \"min_samples_split\": [2, 5, 10],\n",
    "        \"min_samples_leaf\": [1, 2, 4]\n",
    "    },\n",
    "    \"SVM\": {\n",
    "        \"C\": [0.1, 1, 10, 100],\n",
    "        \"kernel\": [\"linear\", \"rbf\", \"poly\"],\n",
    "        \"gamma\": [\"scale\", \"auto\"]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [3, 5, 7, 10],\n",
    "        \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "        \"subsample\": [0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"SVM\": SVC(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "}\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "best_params = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    grid_search = GridSearchCV(model, param_grids[model_name], cv=5, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    best_params[model_name] = grid_search.best_params_\n",
    "    print(f\"Best Parameters for {model_name}: {grid_search.best_params_}\")\n",
    "    print(f\"Best Score: {grid_search.best_score_}\\n\")\n",
    "\n",
    "# Display best parameters\n",
    "print(\"\\nFinal Best Parameters for All Models:\")\n",
    "for model, params in best_params.items():\n",
    "    print(f\"{model}: {params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Encoding target labels (assuming 3 classes: positive, neutral, negative)\n",
    "label_encoder = LabelEncoder()\n",
    "df['sentiment'] = label_encoder.fit_transform(df['sentiment'])\n",
    "\n",
    "# Preparing text features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['text'].astype(str)).toarray()\n",
    "y = df['sentiment']\n",
    "\n",
    "# Splitting dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training models\n",
    "logistic_model = LogisticRegression(max_iter=1000)\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "svm_model =  SVC()\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "# Generating AUC-ROC curve for each model\n",
    "logistic_probs = logistic_model.predict_proba(X_test)\n",
    "rf_probs = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure(figsize=(8, 6))\n",
    "for i, class_label in enumerate(label_encoder.classes_):\n",
    "    fpr_logistic, tpr_logistic, _ = roc_curve(y_test == i, logistic_probs[:, i])\n",
    "    auc_logistic = auc(fpr_logistic, tpr_logistic)\n",
    "\n",
    "    fpr_rf, tpr_rf, _ = roc_curve(y_test == i, rf_probs[:, i])\n",
    "    auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "\n",
    "    plt.plot(fpr_logistic, tpr_logistic, linestyle='--', label=f'Logistic ({class_label}) AUC={auc_logistic:.2f}')\n",
    "    plt.plot(fpr_rf, tpr_rf, linestyle='-', label=f'Random Forest ({class_label}) AUC={auc_rf:.2f}')\n",
    "\n",
    "\n",
    "# Random guess line\n",
    "plt.plot([0, 1], [0, 1], color='grey', linestyle='dotted')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multi-Class ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The performance of the **Random Forest** and **Logistic Regression** classifiers across several categories is shown by the multi-class ROC curve. With AUC scores varying from **0.77 to 0.88** across various classes, both models demonstrate a high degree of predictive power. In most categories, **Logistic Regression** performs marginally better than Random Forest, but its AUC scores are higher in class (3). Both models are effective at differentiating between classes, as evidenced by their overall significantly higher performance compared to random guessing (AUC = 0.5). To enhance performance on the less ideal categories, future actions might include investigating ensemble techniques or fine-tuning hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmZ1v-v1IIyW"
   },
   "source": [
    "\n",
    "## 4. Final Model Selection & Improvement Analysis\n",
    "\n",
    "### Final Model:\n",
    "By comparing the results of each model; Logistic Regression, Random Forest, SVM, and XGBoost, we can view the progression in terms of accuracy and F1-score. Using these comparisons, the model with the best performance is selected for final evaluation and interpretation.\n",
    "\n",
    "### Selection\n",
    "After comparing model performance, model chosen is **Logistic Regression** as the final model. This decision is based on:\n",
    "\n",
    "- **Accuracy**: Logistic Regression achieved an accuracy of **0.7378**, the highest between all tested.\n",
    "- **Class Imbalance Handling**:  Logistic Regression struggles with class 3 but performed well on the majority of classes, especially on class 1 (high recall of 94%).\n",
    "- **Model Simplicity**: Logistic Regression is a relatively simple model, making it easier to interpret and deploy in real-world applications.\n",
    "\n",
    "Looking at performance across all classes, it is justified that Logistic regression was the best.\n",
    "\n",
    "## Evaluation Metrics\n",
    "We used these metrics for Logistic Regression model:\n",
    "\n",
    "- **Accuracy**: Provides a general overview of model performance but may not be sufficient due to class imbalance.\n",
    "- **Precision and Recall**: Helps evaluate how model distinguishes between classes.\n",
    "- **F1-Score**: Balances precision and recall to give a better measure of the model effective ability.\n",
    "- **Confusion Matrix**: Identifies misclassification patterns, which can be useful for refining the model.\n",
    "\n",
    "### Final Evaluation Results\n",
    "\n",
    "- **Accuracy**: 0.7378 = 73.78%\n",
    "- **Precision and Recall**:\n",
    "  - **Class 0**: Precision = 79%, Recall = 66%\n",
    "  - **Class 1**: Precision = 71%, Recall = 94%\n",
    "  - **Class 2**: Precision = 87%, Recall = 20%\n",
    "  - **Class 3**: Precision = 0%, Recall = 0%\n",
    "- **F1-Score**:\n",
    "  - **Highest for Class 1 (0.81)**\n",
    "  - **Lowest for Class 3 (0.00)**\n",
    "\n",
    "### **Interpreting the Evaluation Results**\n",
    "- The model  predicts **73.78% of test samples**.\n",
    "- It performs well on **majority classes **.\n",
    "- **Class imbalance remains an issue**, as **Class 3 is not predicted at all**.\n",
    "\n",
    "## **Next Steps: Refinement**\n",
    "\n",
    "### **1. Handling Class Imbalance**\n",
    "- **Oversampling Minority Classes**: Implement **SMOTE (Synthetic Minority Over-sampling Technique)** to generate synthetic examples for underrepresented classes.\n",
    "- **Class Weight Adjustment**: Modify the class weights during training to ensure the model focuses on the minority classes.\n",
    "\n",
    "### **2. Model Improvement Techniques**\n",
    "- **Hyperparameter Tuning**: Use **Grid Search** to find the optimal parameters for Logistic Regression and improve generalization.\n",
    "- **Ensemble Methods**: Explore **Random Forests or XGBoost** to combine multiple models for better prediction accuracy.\n",
    "\n",
    "### **3. Addressing Rare Classes in the Data**\n",
    "- **Improving Data Collection**: Gather additional data for underrepresented classes to enhance model training.\n",
    "\n",
    "### **4. Model Monitoring & Deployment**\n",
    "- **Model Monitoring**: Once deployed, track performance metrics over time.\n",
    "- **Retraining **: Update the model with new data periodically to maintain accuracy and adaptability.\n",
    "\n",
    "By implementing these, we can improve the model ability to predict minority classes and enhance its real-world application.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MvoMhfdJIJW9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
